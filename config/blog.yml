title: "Actix Blog"
description: "A blog about stuff"
default: light-web-stack
posts:
  - slug: threads-rust
    title: "Low level concurrency"
    author: Neil Ulises
    date: 2022-10-23
    body: >
      Rust has a lot of rules and a strict compiler that can be tedious in the
      begin but is necessary a design like that for build reliable and fast software.
      ![summary](/images/summary.png)
      Every program starts with the main thread only. This thread will execute your
      main function and can be used to spawn more threads if necessary.
      ```rust
        use std::thread;
        fn main() {
          thread::spawn(f);
          thread::spawn(f);
          println!("main thread");
        }
        fn f() {
          println!("another thread");
          let id = thread::current().id();
          println!("Thread id: {id:?}");
        }
      ```
      If we execute this code there is no guarantee that the main thread wait the
      execution of the others threads, you have to invoke the method **join()**.

      ```rust
        let t1 = thread::spawn(f);

        // Waits until the thread has finished executing and returns a std::thread::Result

        t1.join().unwrap();
      ```
      No longer a truncate output. But we still have a diferent order in which the messages
      are printed. The output locking in the println macro **std::io::Stdout::lock()** make
      sure its output doesn't get interrumped.
      Since a thread might run until the very end of the program's execution, the spawn
      function has a 'static lifetime bound on its argument type. In other words, it only
      accepts functions that may be kept around forever, since that reference would
      become invalid the moment the local variable ceases to exist.
      ```rust
        // Getting a value back out of the thread is done by returning it from
        // the clousure. This return value can be obtained from the Result returned
        // by the join method.
        let numbers = Vec::from_iter(0..=1000);

        let t = thread::spawn(move || {
          let len = numbers.len();
          let sum = numbers.into_iter().sum::<usize>();
          // value returned by the thread's clousure
          sum / len
        });

        let average = t.join().unwrap();
        println!("average: {average}");
      ```

      ## Thread Builder

      The spawn function is actually just a convenient shorthand for 
      **std::thread::Builder::new().spawn().unwrap()**. Builder allows you to
      set some settings for the new thread and to give the new thread before spawning it.
      You can use it to configure the **stack size or name**, this helps to debug,
      monitor and to recover more easily if panics a thread.

      ## Scoped Threads

      If we know for sure that a spawned thread will definitely not outlive a certain
      scope, that thread could safely borrow things that do not live forever, such as
      local variables, as long as they outlive that scope.
      ```rust
        let numbers = vec![1,2,3];

        thread::scope(|s| {
          // When the scope ends, all threads that haven't been joined yet are automatically joined.
          s.spawn(|| {
            println!("length: {}", numbers.len());
          });
          s.spawn(|| {
            for n in &numbers {
              println!("{n}");
            }
          })
        })
      ```
      Both threads are concurrently accessing numbers. But will drop error if we
      change in one of them or in the main thread. Something to highlight is a big
      error design in the **Rust 1.0** with a function named scoped, it allowed
      non static captures because returned a JoinGuard instead of a JoinHandle,
      which joined the thread when dropped. Any borrowed data only needed to outlive
      this JoinGuard. Without guarantee that something will be dropped.
      [The Leakpocalypse](https://cglab.ca/~abeinges/blah/everyone-poops/) improve
      the design for safety interface like **std::mem::forget** was upgraded to a
      safe function, to emphatize that forgetting (or leaking) is always a possibility.
      Or **scoped** was redisign that doesn't rely on **Drop** for correctness.

      ## Shared Ownership and Reference Counting

      When sharing data between two threads where neither thread is guaranteed to outlive
      the other, neither of them can be the owner of that data. Any data shared
      between them will need to live as long as the longest living thread.
      To make sure that shared data gets dropped and deallocated, we can't completely
      give up its ownership. Instead, we can share ownership. By keeping track
      of the number of owners, we can make sure the value is dropped only when
      there are no owners left.
      Rc is very similar to a **Box**, except cloning it will not allocate anything
      new, but instead increment a counter stored next to the contained value.
      Both the original and cloned Rc will refer to the same allocation; they share
      ownership.
      ```rust
        use std::rc::Rc;
        let a = Rc::new([1, 2, 3]);
        let b = a.clone();
        assert_eq!(a.as_ptr(), b.as_ptr()); // Same allocation!

        // Rc is not thread safe, instead we can use Arc that guarantees that
        // modifications to the reference counter are indivisible atomic operations,
        // making it safe to use it with multiple threads.
        use std::sync::Arc;
        let a = Arc::new([1,2,3]);
        // Cloning the Arc increments the reference count to two and provides us
        // with a second Arc to the same allocation.
        let b = a.clone();
        thread::spawn(move || dbg!(a));
        // Decrement the Arc to 0 and deallocate the array
        thread::spawn(move || dbg!(b));
      ```
      ![naming_clones](/images/arc.png)

      ## Borrowing and Data Races

      In rust, values can be borrowed in two ways:
      ## Immutable borrowing

      Borrowing something with & gives an immutable reference. Such a reference
      can be copied. Access to the data it references is shared between all copies
      of such a reference. But you can't mutate something through such a reference.
      That might affect other code that's currently borrowing the same data.
      ## Mutable borrowing

      Borrowing something with &mut gives a mutable reference. A mutable borrow
      guarantees it's the only active borrow of that data. This ensures that mutating
      the data will not change anything that other code is currently looking at.
      These two concepts together fully prevent **data races**.
      ## Interior Mutability

      The borrowing rules are limitating between threads communication since no data
      that's accessible by multiple threads can be mutated. A data type with interior
      mutability slightly bends the borrowing rules. As soon as interior mutabile
      type are involved, calling a reference "immutable" or "mutable" becomes confusing
      and inaccurate, since some things can be mutated through both. The more accurate
      terms are **shared** and **exclusive**: a shared reference (&T) can be copied
      and shared with others, while an exclusive reference (&mut T) guarantees it's
      the only exclusive borrowing of that T. For most types, shared references
      do not allow mutation, but there are exceptions.
      Let's take a look at a few types with interior mutability and how they can allow
      mutation through shared references without causing undefined behavior.
      ## Cell

      Allows mutations through a shared reference. To avoid undefined behavior,it only
      allows you to copy the value out (if T is Copy), or replace it with another
      value as a whole. In addition, it can only be used within a single thread.
      ```rust
        use std::cell::Cell;
        fn f(a: &Cell<i32>, b: &Cell<i32>) {
          let before = a.get();
          b.set(b.get() + 1);
          let after = a.get();
          if before != after {
            x(); // might happen
          }
        }
      ```
      It is now possible for the if condition to be true. Because a Cell<i32> has interior
      mutability, the compiler can no longer assume its value won't change as long as
      we have a shared reference to it. Both a and b might refer to the same value,
      such that mutating through b might affect a as well. It may still assume,
      however, that no other threads are accessing the cells concurrently.
      The restrictions on a Cell are not always easy to work with. Since it can't
      directly let us borrow the value it holds, we need to move a value out (leaving
      something in its place), modify it, then put it back, to mutate its contents:
      ```rust
        fn f(v: &Cell<Vec<i32>>) {
          // Replaces the contents of the Cell with an empty Vec
          let mut v2 = v.take();
          v2.push(1);
          // Put the modified Vec back
          v.set(v2);
        }
      ```
      ## RefCell

      Unlike a regular Cell, RefCell allows you to borrow its contents, at a small
      runtime cost. A RefCell does not only hold a T, but also holds a counter
      that keeps track of any outstanding borrows. If you try to borrow it while
      it is already mutably borrowed or vice versa, it will panic, which avoids

      undefined behavior. Just like a Cell, a RefCell can only be used wthin a single thread.
      Borrowing the contents of RefCell is done by calling borrow or borrowmut.
      ```rust
        use std::cell::RefCell;

        fn f(v: &RefCell<Vec<i32>>) {
          // We can modify the Vec directly
          v.borrow_mut().push(1);
        }
      ```
      While Cell and RefCell can be very useful, they become rather useless when we need
      to do something with multiple threads. So let's move on to the types that are
      relevant for concurrency.

      ## Mutex and RwLock

      An RwLock or reader writer lock is the concurrent version of a RefCell. An
      RwLock holds a T and tracks any outstanding borrows. However, unlike a RefCell,
      it does not panic on conflicting borrows. Instead, it blocks the current thread
      putting it to sleep while waiting for conflicting borrows to disappear. We'll
      just have to patiently wait for our turn with the data, after the other threads
      are done with it.
      Borrowing the contents of an RwLock is called locking. By locking it we
      temporarily block concurrent conflicting borrows, allowing us to borrow it
      without causing data races.


      A mutex is very similar, but conceptually slightly simpler. Instead of keeping
      track of the number of shared and exclusive borrows like an RwLock, it only
      allows exclusive borrows.

      ## Atomics

      The atomics types represent the concurrent version of a Cell, only that they
      cannot be of arbitrary size. Because of this, there is no generic Atomic<T> type,
      but there are only specific atomic types such as AtomicU32 and AtomicPtr<T>.
      Atomics often don't directly contain the information that needs to be shared
      between threads. Instead, they are often used as a tool to make it possible
      to share other often bigger things between threads. When atomics are used
      to say something about other data, things can get surprisingly complicated.

      ## UnsafeCell

      An UnsafeCell is the primitive building block for interior mutability.
      Does not come with any conditions or restrictions to avoid undefined behavior.
      Instead, its get() method just gives a raw pointer to the value it wraps, which
      cam only be meaningfully used in unsafe blocks. It leaves it up to the user
      to use it in a way that does not cause any undefined behavior.

      Most commonly, an UnsafeCell is not used directly, but wrapped in another
      type that provides safety through a limited interface, such as Cell or Mutex.
      All types with interior mutability including all types discussed above are
      built on top of UnsafeCell.

      ## Thread Safety: Send and Sync

      The lenguage uses two special traits to keep track of which types can be
      safely used across threads:
      ## Send

      A type is Send if it can be sent to another thread. In other words, if ownership
      of a value of that type can be transferred to another thread. For example,
      Arc<i32> is Send, but Rc<i32> is not.
      ## Sync

      A type is Sync if it can be shared with another thread. A type T is Sync if
      and only if a shared reference to that type, &T, is Send. For example, an i32
      is Sync, but a Cell<i32> is not. (A cell<i32> is Send, however.)


      All primitive types such as i32, bool, and str are both Send and Sync.
      Both of these traits are auto traits, which means that they are automatically
      implemented for your types based on their fields. A struct with fields that
      are all Send and Sync, is itself also Send and Sync.
      ## Locking: Mutexes and RwLocks

      The most commonly used tool for sharing (mutable) data between threads is a mutex,
      which is short for "mutual exlusion". The job of a mutex is to ensure threads
      have exclusive access to some data by temporarily blocking other threads that
      try to access it at the same time.


      Conceptually, a mutex has only two states: locked and unlocked. When a thread
      locks an unlocked mutex, the mutex is marked as locked and the thread can immediately
      continue. When a thread then attempts to lock an already locked mutex, that
      operation will block. The thread is put to seep while it waits for the mutex
      to be unlocked.


      To ensure a locked mutex can only be unlocked by the thread that locked it,
      it does not have an unlock() method. Instead, its **lock()** method returns
      a special type called a **MutexGuard**. This guard represents the guarantee
      that we have locked the mutex. It behaves like an exclusive reference through
      the **DerefMut** trait, giving us exclusive access to the data the mutex
      protects. Unlocking the mutex is done by dropping the guard, we give up our
      ability to access the data, and the Drop implementation of the guard will
      unlock the mutex.
      ```rust
        use std::sync::Mutex;
        fn main() {
          let n = Mutex::new(0);
          thread::scope(|s| {
            for _ in 0..10 {
              s.spawn(|| {
                let mut guard = n.lock().unwrap();
                fot _ in 0..100 {
                  *guard +=1;
                }
              });
            }
          });
          assert_eq!(n.into_iter().unwrap(), 1000);
        }
      ```

      ## Lock Poisoning
      The unwrap() calls in the examples above relate to lock poisoning.
      A Mutex in rust gets marked as poisoned when a thread panics while holding
      the lock. When that happens, the mutex will no longer be locked, but calling
      its lock method will result in an Err to indicate it has been poisoned.
      While lock poisoning might seem like a powerful mechanism, recovering from
      a potentially inconsistent state is not often done in practice. Most code either
      **disregards poison** or uses unwrap() to panic if the lock was poisoned,
      effectively propagating panics to all users of the mutex.
      ## Reader-Writer Lock

      A mutex is only concerned with exclusive access. The MutexGuard will provide
      us an exclusive reference (&mut T) to the protected data, even if we only wanted
      to lock at the data and a shared reference (&T) would have sufficed.


      A reader writer lock is a slightly more complicated version of a mutex that
      understands the difference between exclusive and shared access, and can provide
      either. It has three states: **unlocked, locked by a single writer
      (for exclusive access), and locked by any number of readers (for shared access).**
      It is commonly used for data that is often read by multiple threads, but
      only updated once in a while.
      ## Waiting: Parking and Condition Variables

      When data is mutated by multiple threads, there are many situations where
      they would need to wait for some event, for some condition about the data to
      become true.
      While a mutex does allow threads to wait until it becomes unlocked, it does
      not provide functionality for waiting for any other conditions. If a mutex was
      all we had, we had have to keep locking the mutex to repeatedly check if
      there's anything in the Vec yet.
      ## Thread Parking

      Wait for a notification from another thread is called. A thread can park itself,
      which puts it to sleep, stopping it from consuming any CPU cycles. Another
      thread can then unpark the parked thread, waking it up from its nap.
      Thread parking is available through the std::thread::park() function.
      Lets dive into an example that uses a mutex to share a queue between two
      threads. In the following example, a newly spawned thread will consume
      items from the queue, while the main thread will insert a new item into the
      queue every second. Thread parking is used to make the consuming thread
      wait when the queue is empty.
      ```rust
        use std::collections::VecDeque;
        fn main() {
          let queue = Mutex::new(VecDeque::new());
          thread::scope(|s| {
            // Consuming thread
            let t = s.spawn(|| loop {
              let item = queue.lock().unwrap().pop_front();
              if let Some(item) = item {
                dbg!(item);
              } else {
                thread::park();
              }
            });
            // Producing thread
            for i in 0.. {
              queue.lock().unwrap().push_back(i);
              t.thread().unpark();
              thread::sleep(Duration::from_secs(1));
            }
          });
        }
      ```
      The consuming thread runs an infinite loop in which it pops items out of the
      queue to display them using the dbg macro. When the queue is empty, it stops
      and goes to sleep using the park() function. If it gets unparked, the park()
      call returns, and the loop continues, popping items from the queue again
      until it is empty. And so on.
      ## Condition Variables

      Condition variables are a more commonly used option for waiting for something
      to happen to data protected by a mutex. They have two basic operations:
      **wait** and **notify**. Threads can wait on a condition variable, after
      which they can be woken up when another thread notifies that same condition
      variable. Multiple threads can wait on the same condition variable, and
      notifications can either be sent to one waiting thread, or to all of them.
      ```rust
        use std::sync::Condvar;
        let queue = Mutex::new(VecDeque::new());
        let not_empty = Condvar::new();

        thread::scope(|s| {
          s.spawn(|| {
            loop {
              let mut q = queue.lock().unwrap();
              let item = loop {
                if let Some(item) = q.pop_front() {
                  break item;
                } else {
                  q = not_empty.wait(q).unwrap();
                }
              };
              drop(q);
              dbg!(item);
            }
          });

          for i in 0.. {
            queue.lock().unwrap().push_back(i);
            not_empty.notify_one();
            thread::sleep(Duration::from_secs(1));
          }
        });
      ```
  - slug: light-web-stack
    title: "Great combo in web development"
    author: Neil Campos
    date: 2023-11-07
    body: >
      The stack([Turso](https://turso.tech/), [Htmx](https://htmx.org/), [K3s](https://k3s.io/)),
      You pick the backend language that you want :).

      ## HTMX

      This post only pretend that you ask yourself if the stack that you are using
      is the appropriate in terms of fast delivery and prototyping, and with this said
      my principal issue with modern's frontends(React, Vue...) is that seems that is
      the best option by default, when if you are not creating a heavy client's
      like a spreadsheet or when you really need to have a site offline, maybe is 
      complexity that it's not necessary.
      Years before react towards sense with the SPA and make changes without refresh
      the page, but with libs like htmx tackle this and gives really power to html
      that allow you to focus in your business logic and still having a good client
      experience, the main advantages are:
       * Take away a lot of space in the docker image with 14k of the lib
       * No maintain 2 codebases
       * No decoding and encoding JSON
       * No replicate 2 states
       * Just return html and make real [RESTful](https://htmx.org/essays/how-did-rest-come-to-mean-the-opposite-of-rest/) with SPA benefits

      ![why-htmx](/images/why-htmx.png)

      ## Js is good but not in everything

      This seems a skill issue or a hate to the javascript ecosystem but even
      they are considering more server components with the only incovenient that
      you are tied to build the backend in the environment that they offer like
      with Vercel. All the Js ecosystem it's not going anywhere but there is
      another solutions that makes things more simple when you have to build an
      entire solution that require a solid data model and backend to success!.

      ## Turso

      Is a [fork](https://turso.tech/libsql) of sqlite in the edge
      that comparing with others solutions have the best free plan to build your
      product. Am not a big fan to start for example with a NoSQL solution to start
      something quick, I prefer invest time in create a good schema for the business
      needs and use SQL in the begin with no need to maintain a super database like postgres.
      The [multitenancy](https://turso.tech/multitenancy) is a good reason to build
      a saas on it, to show how simple it is, this 2 commands:

      ```sh
        # Replicate a DB for a client to Tokio
        turso db replicate db_name nrt
        # Get the data for a client
        turso db shell org-zjhg3lp .dump > org.data
      ```

      ## Embedded replicas

      Provide a smooth switch between local and remote database operations, allowing
      the same database replicate in local for reads and the writes for remote, 
      and sync when you really need it.

      ## Platform API

      A RESTful api that allows you to change databases, replicas, and users without
      managing database infrastructure and replication. A simple example:

      ```js
        public databases: DatabaseAPI = {
          create: ({ name, location, image, group }) =>
            this.fetch("/v1/databases", {
            method: "POST",
            body: JSON.stringify({
              name,
              location,
              group,
            }),
          }),
        };
      ```

      ## K3s

      K3s complement really well in our light stack that doesn't mean that can't
      scale, turso and k3s are focus to embedded systems but you can create large
      clusters with high availability setup and an external database for etcd, and
      for turso replicas and multitenancy technique.
      To manipulate your infrastructure am not 100% sure that kubernates is really
      the more simple to work with, Also with solutions like [fly.io](https://fly.io/)
      or [shuttle](https://www.shuttle.rs/) are good options to not interact directly
      with all the complexity of the infrastructure. But I will argue that know how to
      manipulate containers, It will give you advantages in the future.
      I really encourage to create your own lab with minimum hardware and have fun testing your
      services.

      ## What k3s does for you

      For a simple developer like me that in the first time that install k8s
      and use it to deploy a little server with a database was overwhelming that's why
      I opted for k3s, It gives you all preconfigured in a single binary of about 45MB
      that completely implements the Kubernates API's. To ensure lightness they
      removed a lot of extra drivers that are not strictly part of the core, but
      still easily replaceable with external add ons.
       * increase performance
       * lower cost giving you the portability and the scalability that's assoiciated with cloud native applications
       * Internally managed Etcd cluster
       * Internally managed TLS communications
       * Internally managed certificate rotation and distribution
       * Integrated storage provider(localpath provisioner)
       * Low dependency on base operating system

      ![arch](/images/arch.svg)
